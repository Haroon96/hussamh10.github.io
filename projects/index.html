<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hussam Habib's Projects</title>
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <div class="title">
        <span class="large">H</span>ussam <span class="large">H</span>abib
    </div>
    <div class="navbar">
        <button class="win98-button" onclick="window.location.href='../index.html'">Home</button>
        <button class="win98-button" onclick="window.location.href='../projects/index.html'">Projects</button>
        <button class="win98-button" onclick="window.location.href='../blog/index.html'">Blog</button>
        <button class="win98-button" onclick="window.location.href='../res/cv.pdf'">CV</button>
        <button class="win98-button" onclick="window.location.href='../res/statement.pdf'">Research Statement</button>
    </div>
    <div class="content">
        <div class="project">
            <img src="res/youtube.png" alt="youtube Results">
            <div class="project-info">
                <div class="project-title" style="color:#0063bf;">YouTube Recommendations Reinforce Negative Emotions: Auditing Algorithmic Bias with Emotionally-Agentic Sock Puppets. | Submitted 25</div>
                <div class="project-details"><strong>Hussam Habib,</strong>, Rishab Nithyanand</div>
                <div class="project-description">Does YouTube's recommendation algorithm recognize and reinforce emotional preferences? Using a sock-puppet experiment with 500 emotionally-agentic simulated users, we find that YouTube's recommendation algorithm reinforces and amplifies emotions, particularly negative emotions.</div>
                <a href="" target="_blank" class="project-link">[arxiv]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/aceap.png" alt="ACEAP Results">
            <div class="project-info">
                <div class="project-title" style="color:#0063bf;">Characterizing Platform Behavior: Quantifying the Effect of User Interactions on Social Media Homepage Curation. | Submitted 25</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Ryan Stoldt, Raven Maragh-Lloyd, Brian Ekdale, Rishab Nithyanand</div>
                <div class="project-description">How are homepages of social media platforms curated? Using a large sclae audit of  YouTube, X (Twitter), and Reddit we investigate how each platform infer user preferences from user interactions. We characterize platform behaviors as patterns found within the homepage curation.</div>
                <a href="https://arxiv.org/pdf/2407.07227" target="_blank" class="project-link">[arxiv]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/google.png" alt="Google Search Results">
            <div class="project-info">
                <div class="project-title" style="color:#28b009;">Auditing Information Seeking: User's beliefs & attitudes influence Google Search results. | Submitted 25</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Ryan Stoldt, Andrew High, Brian Ekdale, Ashley Peterson, Katy Biddle, Javie Ssozi, Rishab Nithyanand</div>
                <div class="project-description">Modern information seeking processes are often mediated by search engine. In this work, we find <strong>Google Search to present different results</strong> on abortion depending on the user's attitudes towards abortion. The <strong>vocabulary</strong> use to write their queries and their <strong>search history</strong> act as powerful implicit signals that influence the search results.</div>
                <a href="http://arxiv.org/abs/2401.09044" target="_blank" class="project-link">[arxiv]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/actorreact3.png" alt="Act or React">
            <div class="project-info">
                <div class="project-title" style="color:#da9618;">To Act or React: Investigating Proactive Strategies For Online Community Moderation | ICWSM 22</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Maaz Bin Musa, Fareed Zaffar, Rishab Nithyanand</div>
                <div class="project-description">Community-level moderation for Reddit and similar platforms is a complex task. Our analysis show that <strong>subreddits are constantly changing and therefore timely interventions are prohibitively expensive</strong> because of the scale. To address this issue, we propose a flagging tool which aids administrators by <strong>flagging subreddits that exhibit similarly problematic behavior as seen in previously banned communities</strong>.</div>
                <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/19290/19062" target="_blank" class="project-link">[paper]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/moderation4.png" alt="Reddit Moderation">
            <div class="project-info">
                <div class="project-title" style="color:#0063bf;">Reddit and the Fourth Estate: Exploring the magnitude and effects of media influence on community level moderation on Reddit | ICWSM'22</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Rishab Nithyanand</div>
                <div class="project-description">Studying the inconsistencies in Reddit's community-level interventions we observe that negative attention from media towards a subreddit is significantly more likely to result in a ban of a subreddit than high levels of toxicity within the community. <strong>Our results conclude that Reddit's incentives for banning a community are primarily to maintain an image of a civil platform (reactively)</strong>. Measuring whether these misaligned incentives effect the effectiveness of interventions -- <strong>we see media attention can at times exacerbate and promote problematic behavior</strong>.</div>
                <a href="https://ojs.aaai.org/index.php/ICWSM/article/view/19291/19063" target="_blank" class="project-link">[paper]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/radicalization2.png" alt="Radicalization">
            <div class="project-info">
                <div class="project-title" style="color:#b158ac;">Making a Radical Misogynist: How online social engagement with the Manosphere influences traits of radicalization | CSCW'22</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Padmini Srinivasan, Rishab Nithyanand</div>
                <div class="project-description">Online radicalization has been observed to be one of the significant dangers of social media. By measuring users levels of radicalization, we identify online triggers that lead to misogynistic radicalization. We focus entirely on fundamental engagement events and measure their impact on user's behavior. Our findings from a randomized treatment-control experiment show that <strong>participation in problematic communities, interaction with radical users and social status in a platform can influence significant increase in problematic behavior</strong>.</div>
                <a href="https://arxiv.org/pdf/2202.08805.pdf" target="_blank" class="project-link">[paper]</a>
            </div>
        </div>

        <div class="project">
            <img src="res/morbid3.png" alt="Morbid Realities">
            <div class="project-info">
                <div class="project-title" style="color:#484896;">The Morbid Realities of Social Media: An Investigation into the Misinformation Shared by the Deceased Victims of COVID-19 | ICWSM'23</div>
                <div class="project-details"><strong>Hussam Habib,</strong> Rishab Nithyanand</div>
                <div class="project-description">We investigate the misinformation shared by the deceased victims of Covid-19. Using a crowdsourced dataset of screenshots of Facebook posts shared by victims of Covid-19 with anti-vaccination and covid denial beliefs. We find <strong>Covid-19 narratives to be politicized, being sourced from biased and uncredible sources, and shared by right-winged political personalities.</strong> Results from this study bring insights into the responsibility of political elites in shaping public discourse and the platform's role in dampening the reach of harmful misinformation.</div>
                <a href="https://arxiv.org/pdf/2209.09964.pdf" target="_blank" class="project-link">[paper]</a>
            </div>
        </div>
    </div>
</body>
</html>