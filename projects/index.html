<!DOCTYPE html>
<html>
    <head>
        <link rel="stylesheet" href="projectstyles.css" />
        <meta name="viewport" content="width=device-width, initial-scale=1">

    </head>

    <body style="background-color: #f6f2ef">
        <div class="header">
            <p class="name"> Hussam Habib </p>
        </div>
        <p class="nav">
            <a class="link" href="../index.html">home</a>&nbsp;
            <a class="link" href="/index.html">projects</a>&nbsp;
            <a class="link "href="../blog/index.html">blog</a>&nbsp;
            <a class="link" href="../res/cv.pdf" target="_blank">cv</a>&nbsp;
        </p>

        


        <div class="main">

            <div class="left">
                <img class="plot" src="res/actorreact3.png">
                <p class="links"><a class="links" href="https://ojs.aaai.org/index.php/ICWSM/article/view/19290/19062" target="_blank">[paper]</a></p>
            </div>


            <div class="right"> 

                <p class="text">
                    <strong style="color:#da9618;"> To Act or React: Investigating Proactive Strategies For Online Community Moderation</strong> <strong>| ICWSM 22 </strong>
                    <br>
                    <strong>Hussam Habib,</strong>  Maaz Bin Musa, Fareed Zaffar, Rishab Nithyanand 
                    <br>
                    <br>
                </p>
                <p class="text-small">
                    Community-level moderation for Reddit and similar platforms is a complex task. Our analysis show that <strong> subreddits are constantly changing and therefore timely interventions are prohibitively expesnsive </strong> because of the scale. To address this issue, we propose a flagging tool which aids administrators by <strong> flagging subreddits that exhibit similarly problematic behavior as seen in previously banned communities </strong>.
                </p>

            </div>

        </div>

        <div class="main">

            <div class="left">
                <img class="plot" src="res/moderation4.png">
                <p class="links"><a class="links" href="https://ojs.aaai.org/index.php/ICWSM/article/view/19291/19063" target="_blank">[paper]</a></p>
            </div>


            <div class="right"> 

                <p class="text">
                    <strong style="color:#0063bf;"> Reddit and the Fourth Estate: Exploring the magnitude and effects of media influence on community level moderation on Reddit
                    </strong> <strong>| ICWSM'22 </strong>
                    <br>
                    <strong>Hussam Habib,</strong> Rishab Nithyanand 
                    <br>
                    <br>
                </p>


                <p class="text-small">
                    Studying the inconsistencies in Reddit's community-level interventions we observe that negative attention from media towards a subreddit is significantly more likely to result in a ban of a subreddit than high levels of toxicity within the community.<strong> Our results conclude that Reddit's incentives for banning a community are primarily to maintain an image of a civil platform (reactively) </strong>. Measuring whether these misaligned incentives effect the effectiveness of interventions -- <strong>we see media attention can at times exacerbate and promote problematic behavior</strong>.
                </p>


            </div>

        </div>

        <div class="main">

            <div class="left">
                <img class="plot" src="res/radicalization2.png">
                <p class="links"><a class="links" href="https://arxiv.org/pdf/2202.08805.pdf" target="_blank">[paper]</a></p>
            </div>


            <div class="right"> 

                <p class="text">
                    <strong style="color:#b158ac;"> Making a Radical Misogynist: How online social engagement with the Manosphere influences traits of radicalization
                    </strong> <strong>| CSCW'22 </strong>
                    <br>
                    <strong>Hussam Habib,</strong> Padmini Srinivasan, Rishab Nithyanand 
                    <br>
                    <br>
                </p>


                <p class="text-small">
                    Online radicalization has been observed to be one of the significant dangers of social media. By measuring users levels of radicalization, we identify online triggers that lead to misogynistic radicalization. We focus entirely on fundamental engagement events and measure their impact on user's behavior. Our findings from a randomized treatment-control experiment show that <strong> participation in problematic communities, interaction with radical users and social status in a platform can influence significant increase in problematic behavior </strong>.
                </p>


            </div>

        </div>
<!-- 
        <div class="main">

            <div class="left">
                <img class="plot" src="res/vaccination.png">
                <p class="links"> [paper] </p>
            </div>


            <div class="right"> 

                <p class="text">
                    <strong style="color:#b158ac;"> Relationships Among Vaccination Attitudes, Social Media Use, and Activist vs. Radical Behavior.
                    </strong> <strong>| ICA'22 </strong>
                    <br>
                    Ryan Stoldt, Andrew High, Ashley Peterson, Kathryn Biddle, Raven Maragh-Lloyd, Rishab Nithyanand, Brian Ekdale, Timothy Havens, <strong>Hussam Habib,</strong> John Thiede
                    <br>
                    <br>
                </p>


                <p class="text">
                    Examining how people's beliefs about vaccines and their social media use together affect the radical behaviors for the support of their beliefs
                </p>


            </div>

        </div> -->

    </body>

</html>